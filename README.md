# yt-shorts-wan

Wan2.2 Image-to-Video (I2V) deployment for RunPod Serverless - Part of the YouTube Shorts AI Content Generator pipeline.

## Overview

This service converts images (generated by FLUX.1-dev) into short videos using Alibaba's Wan2.2-I2V model. The output is optimized for YouTube Shorts (vertical format, 5 seconds).

## Architecture

```
FLUX.1-dev (yt-shorts-flux)
    ↓ 5× PNG images (832×1536)
Wan2.2-I2V (this repo)
    ↓ 5× MP4 videos (5s @ 16fps)
YouTube Shorts
```

## Model Specifications

- **Model**: [Wan-AI/Wan2.2-I2V-A14B-Diffusers](https://huggingface.co/Wan-AI/Wan2.2-I2V-A14B-Diffusers)
- **Parameters**: 14B (Mixture-of-Experts architecture)
- **Input**: Base64 encoded image
- **Output**: MP4 video
- **Resolution**: 480P (optimized for vertical Shorts)
- **FPS**: 16 (81 frames = 5 seconds)
- **VRAM**: Optimized for 24GB GPUs (A40, RTX 6000 Ada)

## API Usage

### Request

```json
{
  "image": "base64_encoded_image_string",
  "prompt": "Cinematic camera movement, gentle motion",
  "negative_prompt": "blurry, low quality",
  "num_frames": 81,
  "guidance_scale": 3.5,
  "num_inference_steps": 40,
  "seed": 42,
  "fps": 16
}
```

### Response

```json
{
  "status": "success",
  "video": {
    "video_base64": "base64_encoded_mp4",
    "fps": 16,
    "num_frames": 81,
    "width": 832,
    "height": 480
  },
  "model": "Wan-AI/Wan2.2-I2V-A14B-Diffusers"
}
```

## Local Development

### Prerequisites

- Docker
- Hugging Face token with access to Wan2.2 models

### Build

```bash
docker build --build-arg HF_TOKEN=hf_xxx -t yt-shorts-wan .
```

### Test

```bash
docker run -p 8080:8080 yt-shorts-wan
```

## GitHub Secrets

Required secrets for CI/CD:

| Secret | Description |
|--------|-------------|
| `DOCKERHUB_USERNAME` | Docker Hub username (`jaxnlindemann`) |
| `DOCKERHUB_TOKEN` | Docker Hub access token (Read & Write) |
| `HF_TOKEN` | Hugging Face token (for gated model access) |

## Key Features

### VRAM Optimizations
- Text encoder CPU offloading (~4-6GB savings)
- VAE slicing and tiling
- Efficient memory allocation

### Quality Features
- Wan2.2 supports **negative prompts** (unlike FLUX.1-dev)
- Mixture-of-Experts for better motion consistency
- Cinematic aesthetics from training data

## Deployment

1. Push to `main` branch triggers GitHub Actions
2. Docker image built and pushed to `jaxnlindemann/yt-shorts-wan:latest`
3. On RunPod: Click **Redeploy** in your deployment

## Performance

- **Cold Start**: ~15-20s (model loading)
- **Inference**: ~60-90s per video (5s @ 16fps, 480P)
- **GPU**: A40 (24GB VRAM) - recommended

## Related Repos

- [yt-shorts-flux](https://github.com/canugurlu/yt-shorts-flux) - Text-to-Image generation

## License

Apache 2.0 - Wan2.2 models are licensed under Apache 2.0
